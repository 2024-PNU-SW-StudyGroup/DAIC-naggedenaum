# -------------------------------------------------------------
# Docâ€¯Scheduler â€“ Streamlitâ€¯ì•± (singleâ€‘file)
# -------------------------------------------------------------
# ì£¼ìš” ê¸°ëŠ¥
# 1) ë¬¸ì„œ/ì´ë¯¸ì§€ ì—…ë¡œë“œ â†’ Upstage Documentâ€¯Parse API ë¡œ ì›ë¬¸ ì¶”ì¶œ
# 2) ì¼ì •Â·ë§ˆê°ì¼ í‚¤ì›Œë“œ íŒŒì‹± â†’ Task ë¦¬ìŠ¤íŠ¸ ìƒì„±
# 3) 3Â ì¢… Worksheet í…œí”Œë¦¿(íƒ€ì„ë¼ì¸Â·ë¦¬ìŠ¤íŠ¸Â·ì¹¸ë°˜) ì¤‘ í•˜ë‚˜ ì„ íƒí•´ ì‹œê°í™”
# 4) ê²°ê³¼ CSV / Markdown ë‹¤ìš´ë¡œë“œ & ì¬ì‚¬ìš© ê°€ëŠ¥
# -------------------------------------------------------------
# ìš”êµ¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ê°€ìƒí™˜ê²½ì—ì„œ ì„¤ì¹˜ ê¶Œì¥)
#   pip install streamlit requests python-dotenv pandas plotly python-dateutil
# -------------------------------------------------------------

import os
import re
import uuid
from datetime import datetime, timedelta
from typing import List, Dict

import requests
import streamlit as st
import pandas as pd
import plotly.express as px
from dateutil import parser as dtparse
from dotenv import load_dotenv

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY", "")
if not UPSTAGE_API_KEY:
    st.error("í™˜ê²½ ë³€ìˆ˜ UPSTAGE_API_KEY ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

UPSTAGE_PARSE_URL = "https://api.upstage.ai/v1/document-ai/document-parse"
HEADERS = {"Authorization": f"Bearer {UPSTAGE_API_KEY}"}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â UI ì„¤ì •
st.set_page_config(page_title="Docâ€¯Scheduler", layout="wide")
st.title("ğŸ“„ DocÂ Scheduler â€“ ë¬¸ì„œ ê¸°ë°˜ ì¼ì • ì›Œí¬ì‹œíŠ¸")
st.markdown("ì—…ë¡œë“œí•œ PDF/HWP/PPTX/ì´ë¯¸ì§€ì—ì„œ **ì¼ì •Â·ë§ˆê°ì¼**ì„ ì¶”ì¶œí•´ ì›í•˜ëŠ” í˜•ì‹ì˜ ì›Œí¬ì‹œíŠ¸ë¥¼ ë°”ë¡œ ë§Œë“­ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” â€“ ì—…ë¡œë“œ & ì˜µì…˜
with st.sidebar:
    st.header("1ï¸âƒ£ ë¬¸ì„œ ì—…ë¡œë“œ")
    files = st.file_uploader(
        "PDF Â· HWP Â· DOCX Â· PPTX Â· ì´ë¯¸ì§€(JPG/PNG) ë‹¤ì¤‘ ì„ íƒ ì§€ì›",
        accept_multiple_files=True,
    )

    st.header("2ï¸âƒ£ íŒŒì‹± & ì›Œí¬ì‹œíŠ¸ ì˜µì…˜")
    output_fmt = st.selectbox("UpstageÂ ì¶œë ¥ í˜•ì‹", ["text", "markdown", "html"])
    split_unit = st.selectbox("Split ë‹¨ìœ„", ["none", "page", "element"])

    st.divider()
    ws_template = st.radio(
        "âœï¸ ì›Œí¬ì‹œíŠ¸ í…œí”Œë¦¿", ["TimelineÂ (Gantt)", "Checklist", "Kanban"],
        help="SOLARÂ AI ì„ í˜¸ë„ëŠ” ë¯¸ì§€ì› â€“ ê¸°ë³¸ 3Â ì¢… í…œí”Œë¦¿ ì œê³µ"
    )

    run_button = st.button("ğŸš€ íŒŒì‹± ì‹¤í–‰", disabled=not files)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í—¬í¼ í•¨ìˆ˜

def call_upstage(file_name: str, file_bytes: bytes) -> str:
    """UpstageÂ DocumentÂ ParseÂ API í˜¸ì¶œ â†’ ì›ë¬¸ í…ìŠ¤íŠ¸ ë°˜í™˜"""
    resp = requests.post(
        UPSTAGE_PARSE_URL,
        headers=HEADERS,
        timeout=120,
        files={"document": (file_name, file_bytes)},
        data={
            "output_format": output_fmt,
            "split": split_unit,
            "ocr": "auto",
        },
    )
    resp.raise_for_status()
    # content êµ¬ì¡°: {"content": {"text"|"html"|"markdown": "..."}}
    return resp.json()["content"][output_fmt]


def extract_tasks(text: str) -> List[Dict]:
    """í…ìŠ¤íŠ¸ì—ì„œ (ë‚ ì§œÂ·ì‹œê°„) íŒ¨í„´ì„ ì°¾ì•„ TaskÂ ë¦¬ìŠ¤íŠ¸ë¡œ ë‹¨ìˆœ ì¶”ì¶œ.
    ê·œì¹™ (heuristic)
      â€¢ YYYY-MM-DD, YYYY/MM/DD, MM/DD, MM-DD, DDì¼ ë“± ë‚ ì§œ íŒ¨í„´
      â€¢ ê°™ì€ ì¤„/ì•ë’¤ 30ì ì´ë‚´ ë¬¸ì¥ì„ ì œëª©ìœ¼ë¡œ ê°„ì£¼
    """
    # â‘  ë‚ ì§œÂ ì •ê·œì‹ íŒ¨í„´ ëª¨ìŒ
    date_patterns = [
        r"\d{4}[./-]\d{1,2}[./-]\d{1,2}",     # 2025-05-28 / 2025.05.28 / 2025/05/28
        r"\d{1,2}[./-]\d{1,2}",               # 05-28 / 05/28 / 5.28
        r"\d{1,2}ì¼",                          # 28ì¼
    ]
    regex = re.compile("|".join(date_patterns))

    tasks = []
    for line in text.splitlines():
        line = line.strip()
        if not line:
            continue
        m = regex.search(line)
        if not m:
            continue
        date_str = m.group()
        try:
            # dateutilÂ parse â€“ ë…„ë„ ìƒëµ ì‹œ ì˜¬í•´ë¡œ ê°€ì •
            dt = dtparse.parse(date_str, default=datetime.today())
            title = line.replace(date_str, "").strip(" -:Â·.\u2022") or "ë¬´ì œ"
            tasks.append({
                "Task": title,
                "Start": dt.date(),
                "Finish": (dt + timedelta(hours=1)).date(),  # FinishÂ =Â StartÂ (+1Â day ì‹œ í‘œì‹œìš©)
                "Deadline": dt.date(),
            })
        except (ValueError, OverflowError):
            continue
    return tasks


def render_timeline(df: pd.DataFrame):
    fig = px.timeline(df, x_start="Start", x_end="Finish", y="Task", color="Task")
    fig.update_yaxes(autorange="reversed")  # earliest at top
    st.plotly_chart(fig, use_container_width=True)


def render_checklist(df: pd.DataFrame):
    st.markdown("### âœ”ï¸ Checklist")
    for i, row in df.iterrows():
        st.checkbox(f"{row['Deadline']}Â â€“Â {row['Task']}", key=f"chk_{i}")


def render_kanban(df: pd.DataFrame):
    st.markdown("### ğŸ—‚ï¸ KanbanÂ (Board ë‹¨ìˆœ êµ¬í˜„)")
    cols = st.columns(3)
    for idx, (_, row) in enumerate(df.iterrows()):
        with cols[idx % 3]:
            st.info(f"**{row['Task']}**\n\nğŸ“…Â {row['Deadline']}")


def worksheet_view(df: pd.DataFrame):
    if ws_template == "TimelineÂ (Gantt)":
        render_timeline(df)
    elif ws_template == "Checklist":
        render_checklist(df)
    else:
        render_kanban(df)

    st.download_button(
        "ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
        data=df.to_csv(index=False).encode("utf-8-sig"),
        file_name=f"worksheet_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv",
    )
    st.download_button(
        "ğŸ“¥ Markdown ë‹¤ìš´ë¡œë“œ",
        data=df.to_markdown(index=False).encode(),
        file_name="worksheet.md",
        mime="text/markdown",
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‹¤í–‰ ë¡œì§
if run_button and files:
    all_tasks: List[Dict] = []

    for f in files:
        with st.spinner(f"UpstageÂ íŒŒì‹± ì¤‘â€¦  ({f.name})"):
            try:
                parsed_text = call_upstage(f.name, f.getvalue())
            except Exception as e:
                st.error(f"{f.name}: API í˜¸ì¶œ ì‹¤íŒ¨ â€“ {e}")
                continue

        # ì¶”ì¶œ
        tasks = extract_tasks(parsed_text)
        if not tasks:
            st.warning(f"â” {f.name} ì—ì„œ ì¼ì • íŒ¨í„´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            continue
        st.success(f"âœ… {f.name} â†’ {len(tasks)}Â ê±´ ì¶”ì¶œ")
        all_tasks.extend(tasks)

    if all_tasks:
        st.divider()
        st.header("3ï¸âƒ£ ì›Œí¬ì‹œíŠ¸ ê²°ê³¼")
        df_tasks = pd.DataFrame(all_tasks)
        worksheet_view(df_tasks)
    else:
        st.error("ì¶”ì¶œëœ ì¼ì • ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒ¨í„´(ë‚ ì§œÂ·ì‹œê°„) í¬í•¨ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â í‘¸í„°
with st.expander("â„¹ï¸Â ì•± ì •ë³´ / í–¥í›„ ë¡œë“œë§µ"):
    st.markdown(
        "* SOLARÂ AI ì„ í˜¸ í…œí”Œë¦¿ ì¶”ì²œ, Notion/GoogleÂ Calendar ì—°ë™, Diffâ€‘Privacy ê°•í™” ë“±ì€ ë¡œë“œë§µì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."\
    )
